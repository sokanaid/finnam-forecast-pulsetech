{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ FORECAST - –ó–∞–ø—É—Å–∫ —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ Google Drive\n",
        "\n",
        "**–ö–æ–º–∞–Ω–¥–∞ Pulsetech**\n",
        "\n",
        "–≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –±–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç —Å Google Drive –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ.\n",
        "\n",
        "‚è±Ô∏è **–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è**: –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "‚öôÔ∏è **Runtime**: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ **CPU** (GPU –Ω–µ –Ω—É–∂–µ–Ω!)\n",
        "\n",
        "---\n",
        "\n",
        "## üìù –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:\n",
        "\n",
        "–û–∂–∏–¥–∞–µ—Ç—Å—è —Ñ–∞–π–ª `forecast_data.zip` –Ω–∞ Google Drive —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π:\n",
        "```\n",
        "forecast_data/\n",
        "  ‚îú‚îÄ‚îÄ candles.csv      ‚Üí train_candles.csv\n",
        "  ‚îú‚îÄ‚îÄ news.csv         ‚Üí train_news.csv\n",
        "  ‚îú‚îÄ‚îÄ candles_2.csv    ‚Üí test_candles.csv (public+private)\n",
        "  ‚îî‚îÄ‚îÄ news_2.csv       ‚Üí test_news.csv\n",
        "```\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Runtime (–í–ê–ñ–ù–û!)\n",
        "\n",
        "**–í—ã–±–µ—Ä–∏—Ç–µ CPU runtime:**\n",
        "1. –í –º–µ–Ω—é —Å–≤–µ—Ä—Ö—É: `Runtime` ‚Üí `Change runtime type`\n",
        "2. –í –ø–æ–ª–µ `Hardware accelerator` –≤—ã–±–µ—Ä–∏—Ç–µ **None** (—ç—Ç–æ CPU)\n",
        "3. –ù–∞–∂–º–∏—Ç–µ `Save`\n",
        "\n",
        "‚ö†Ô∏è **GPU –Ω–µ –Ω—É–∂–µ–Ω –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# –ú–æ–Ω—Ç–∏—Ä—É–µ–º Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"‚úÖ Google Drive –ø–æ–¥–∫–ª—é—á–µ–Ω!\")\n",
        "print(\"\\nüìÇ –ü—É—Ç—å –∫ –≤–∞—à–∏–º —Ñ–∞–π–ª–∞–º: /content/drive/MyDrive/\")\n",
        "print(\"\\n‚ö†Ô∏è –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ñ–∞–π–ª forecast_data.zip –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –∫–æ—Ä–Ω–µ MyDrive\")\n",
        "print(\"   –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º —à–∞–≥–µ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ö–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π\n",
        "!git clone https://github.com/sokanaid/finnam-forecast-pulsetech.git\n",
        "%cd finnam-forecast-pulsetech\n",
        "\n",
        "print(\"‚úÖ –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å–∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω!\")\n",
        "print(\"\\nüì¶ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏...\")\n",
        "\n",
        "# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "print(\"‚úÖ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "# –ü—É—Ç—å –∫ –≤–∞—à–µ–º—É ZIP —Ñ–∞–π–ª—É –Ω–∞ Google Drive\n",
        "# –ò–ó–ú–ï–ù–ò–¢–ï –ü–£–¢–¨ –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –¥—Ä—É–≥–æ–π –ø–∞–ø–∫–µ!\n",
        "zip_path = '/content/drive/MyDrive/forecast_data.zip'\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞\n",
        "if not os.path.exists(zip_path):\n",
        "    print(f\"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {zip_path}\")\n",
        "    print(\"\\nüìÇ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É!\")\n",
        "    print(\"   –í–æ–∑–º–æ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã:\")\n",
        "    print(\"   - /content/drive/MyDrive/forecast_data.zip\")\n",
        "    print(\"   - /content/drive/MyDrive/Colab Notebooks/forecast_data.zip\")\n",
        "    print(\"\\nüí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É –Ω–∏–∂–µ —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª:\")\n",
        "    print(\"   !find /content/drive/MyDrive -name 'forecast_data.zip'\")\n",
        "else:\n",
        "    print(f\"‚úÖ –§–∞–π–ª –Ω–∞–π–¥–µ–Ω: {zip_path}\")\n",
        "    file_size_mb = os.path.getsize(zip_path) / 1024 / 1024\n",
        "    print(f\"üì¶ –†–∞–∑–º–µ—Ä: {file_size_mb:.1f} MB\")\n",
        "    \n",
        "    print(\"\\nüìÇ –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ...\")\n",
        "    \n",
        "    # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –≤ —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall('.')\n",
        "    \n",
        "    print(\"‚úÖ –î–∞–Ω–Ω—ã–µ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω—ã!\")\n",
        "    \n",
        "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É\n",
        "    print(\"\\nüìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤:\")\n",
        "    !ls -lh forecast_data/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã –ø–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –∫–æ—Ç–æ—Ä—É—é –æ–∂–∏–¥–∞–µ—Ç –Ω–∞—à –∫–æ–¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫\n",
        "!mkdir -p data/raw\n",
        "\n",
        "# –ö–æ–ø–∏—Ä—É–µ–º –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã\n",
        "file_mapping = {\n",
        "    'forecast_data/candles.csv': 'data/raw/train_candles.csv',\n",
        "    'forecast_data/news.csv': 'data/raw/train_news.csv',\n",
        "    'forecast_data/candles_2.csv': 'data/raw/public_test_candles.csv',\n",
        "    'forecast_data/news_2.csv': 'data/raw/test_news.csv',\n",
        "}\n",
        "\n",
        "print(\"üìã –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∏ –∫–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã:\\n\")\n",
        "\n",
        "for source, target in file_mapping.items():\n",
        "    if os.path.exists(source):\n",
        "        shutil.copy(source, target)\n",
        "        size_mb = os.path.getsize(target) / 1024 / 1024\n",
        "        \n",
        "        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏ –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏\n",
        "        df = pd.read_csv(target, nrows=2)\n",
        "        print(f\"‚úÖ {source}\")\n",
        "        print(f\"   ‚Üí {target}\")\n",
        "        print(f\"   –†–∞–∑–º–µ—Ä: {size_mb:.1f} MB, –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}\")\n",
        "        print()\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {source}\")\n",
        "        print()\n",
        "\n",
        "# –î–ª—è private_test —Å–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é public (–µ—Å–ª–∏ –Ω–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞)\n",
        "if not os.path.exists('data/raw/private_test_candles.csv'):\n",
        "    shutil.copy('data/raw/public_test_candles.csv', 'data/raw/private_test_candles.csv')\n",
        "    print(\"üìù –°–æ–∑–¥–∞–Ω–∞ –∫–æ–ø–∏—è public_test ‚Üí private_test\")\n",
        "\n",
        "print(\"\\n‚úÖ –î–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. üöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
        "\n",
        "–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–∏–Ω—É—Ç –¥–æ —á–∞—Å–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üéì –ù–ê–ß–ê–õ–û –û–ë–£–ß–ï–ù–ò–Ø\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "!python train.py\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print(f\"\\n‚è±Ô∏è –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {elapsed/60:.2f} –º–∏–Ω—É—Ç\")\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –º–æ–¥–µ–ª–∏ —Å–æ–∑–¥–∞–Ω—ã\n",
        "if os.path.exists('models/forecast_models.pkl'):\n",
        "    size_mb = os.path.getsize('models/forecast_models.pkl') / 1024 / 1024\n",
        "    print(f\"‚úÖ –ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: models/forecast_models.pkl ({size_mb:.1f} MB)\")\n",
        "else:\n",
        "    print(\"‚ùå –û—à–∏–±–∫–∞: –º–æ–¥–µ–ª–∏ –Ω–µ —Å–æ–∑–¥–∞–Ω—ã!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. üîÆ –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"üîÆ –°–û–ó–î–ê–ù–ò–ï –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "!python predict.py\n",
        "\n",
        "if os.path.exists('submission.csv'):\n",
        "    print(\"\\n‚úÖ submission.csv —Å–æ–∑–¥–∞–Ω!\")\n",
        "else:\n",
        "    print(\"\\n‚ùå –û—à–∏–±–∫–∞: submission.csv –Ω–µ —Å–æ–∑–¥–∞–Ω!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. üìä –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ –º–µ—Ç—Ä–∏–∫\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "submission = pd.read_csv('submission.csv')\n",
        "prob_cols = [f'p{i}' for i in range(1, 21)]\n",
        "\n",
        "print('=' * 70)\n",
        "print('üìä –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í')\n",
        "print('=' * 70)\n",
        "\n",
        "print(f'\\n‚úÖ –†–∞–∑–º–µ—Ä: {len(submission)} —Å—Ç—Ä–æ–∫')\n",
        "print(f'‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤: {submission[\"ticker\"].nunique()}')\n",
        "print(f'‚úÖ –¢–∏–∫–µ—Ä—ã: {list(submission[\"ticker\"].unique())}')\n",
        "\n",
        "# –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
        "all_probs = submission[prob_cols].values.flatten()\n",
        "print(f'\\nüìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π:')\n",
        "print(f'   –°—Ä–µ–¥–Ω–µ–µ: {all_probs.mean():.4f}')\n",
        "print(f'   Std: {all_probs.std():.4f}')\n",
        "print(f'   Min: {all_probs.min():.4f}')\n",
        "print(f'   Max: {all_probs.max():.4f}')\n",
        "print(f'   –ú–µ–¥–∏–∞–Ω–∞: {np.median(all_probs):.4f}')\n",
        "\n",
        "# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ\n",
        "print(f'\\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π:')\n",
        "ranges = [(0, 0.2), (0.2, 0.4), (0.4, 0.6), (0.6, 0.8), (0.8, 1.0)]\n",
        "for low, high in ranges:\n",
        "    count = ((all_probs >= low) & (all_probs < high)).sum()\n",
        "    pct = count / len(all_probs) * 100\n",
        "    print(f'   [{low:.1f}-{high:.1f}): {pct:5.1f}% ({count:,} –∑–Ω–∞—á–µ–Ω–∏–π)')\n",
        "\n",
        "# –¢—Ä–µ–Ω–¥ –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–º\n",
        "print(f'\\nüìâ –°—Ä–µ–¥–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–º:')\n",
        "horizon_means = []\n",
        "for i in range(1, 21):\n",
        "    mean_val = submission[f'p{i}'].mean()\n",
        "    horizon_means.append(mean_val)\n",
        "    print(f'   –ì–æ—Ä–∏–∑–æ–Ω—Ç {i:2d}: {mean_val:.4f}')\n",
        "\n",
        "# –¢—Ä–µ–Ω–¥\n",
        "trend_diff = horizon_means[0] - horizon_means[-1]\n",
        "if trend_diff > 0:\n",
        "    print(f'\\nüìâ –¢—Ä–µ–Ω–¥: –£–ë–´–í–ê–Æ–©–ò–ô (Œî={trend_diff:.4f})')\n",
        "    print('   ‚úÖ –õ–æ–≥–∏—á–Ω–æ: —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Å–Ω–∏–∂–∞–µ—Ç—Å—è —Å –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–º')\n",
        "else:\n",
        "    print(f'\\nüìà –¢—Ä–µ–Ω–¥: –ù–ï —É–±—ã–≤–∞—é—â–∏–π (Œî={trend_diff:.4f})')\n",
        "\n",
        "print('\\n' + '=' * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# 1. –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π\n",
        "axes[0, 0].hist(all_probs, bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[0, 0].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å')\n",
        "axes[0, 0].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')\n",
        "axes[0, 0].axvline(all_probs.mean(), color='red', linestyle='--', label=f'–°—Ä–µ–¥–Ω–µ–µ: {all_probs.mean():.3f}')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# 2. –¢—Ä–µ–Ω–¥ –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–º\n",
        "axes[0, 1].plot(range(1, 21), horizon_means, marker='o', linewidth=2)\n",
        "axes[0, 1].set_title('–°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–º', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('–ì–æ—Ä–∏–∑–æ–Ω—Ç (–¥–Ω–∏)')\n",
        "axes[0, 1].set_ylabel('–°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å')\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "axes[0, 1].axhline(0.5, color='gray', linestyle='--', alpha=0.5)\n",
        "\n",
        "# 3. Boxplot –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–º (–∫–∞–∂–¥—ã–µ 4 –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞)\n",
        "boxplot_data = [submission[f'p{i}'].values for i in [1, 5, 10, 15, 20]]\n",
        "axes[1, 0].boxplot(boxplot_data, labels=['1–¥', '5–¥', '10–¥', '15–¥', '20–¥'])\n",
        "axes[1, 0].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–º', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_ylabel('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å')\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# 4. –°—Ä–µ–¥–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ —Ç–∏–∫–µ—Ä–∞–º\n",
        "ticker_means = submission.groupby('ticker')[prob_cols].mean().mean(axis=1).sort_values()\n",
        "axes[1, 1].barh(ticker_means.index, ticker_means.values)\n",
        "axes[1, 1].set_title('–°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ —Ç–∏–∫–µ—Ä–∞–º', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('–°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å')\n",
        "axes[1, 1].axvline(0.5, color='gray', linestyle='--', alpha=0.5)\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≥–æ—Ç–æ–≤–∞!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# –°–∫–∞—á–∏–≤–∞–µ–º submission\n",
        "if os.path.exists('submission.csv'):\n",
        "    files.download('submission.csv')\n",
        "    print(\"‚úÖ submission.csv —Å–∫–∞—á–∞–Ω!\")\n",
        "else:\n",
        "    print(\"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω!\")\n",
        "\n",
        "# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ Google Drive\n",
        "save_to_drive = input(\"\\nüíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å submission.csv –≤ Google Drive? (y/n): \")\n",
        "if save_to_drive.lower() == 'y':\n",
        "    output_path = '/content/drive/MyDrive/submission_forecast.csv'\n",
        "    shutil.copy('submission.csv', output_path)\n",
        "    print(f\"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_path}\")\n",
        "\n",
        "print(\"\\nüéâ –ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä—å –º–æ–∂–µ—Ç–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å submission.csv –Ω–∞ –ª–∏–¥–µ—Ä–±–æ—Ä–¥\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ –ì–æ—Ç–æ–≤–æ!\n",
        "\n",
        "**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**\n",
        "- ‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "- ‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–æ–∑–¥–∞–Ω—ã\n",
        "- ‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã\n",
        "- ‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞\n",
        "- ‚úÖ submission.csv –≥–æ—Ç–æ–≤ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏\n",
        "\n",
        "**–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:**\n",
        "1. –û—Ç–ø—Ä–∞–≤—å—Ç–µ `submission.csv` –Ω–∞ –ª–∏–¥–µ—Ä–±–æ—Ä–¥\n",
        "2. –û–±–Ω–æ–≤–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏\n",
        "3. –°—Ä–∞–≤–Ω–∏—Ç–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏\n",
        "\n",
        "---\n",
        "\n",
        "**–ö–æ–º–∞–Ω–¥–∞ Pulsetech** üöÄ\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
