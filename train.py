"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ FORECAST
"""
import sys
import time
import argparse
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent))

from src.data_loader import DataLoader
from src.feature_engineering import FeatureEngineer
from src.model import ForecastModel
from src.config import RANDOM_SEED, MODELS_DIR, TRAIN_CANDLES, TRAIN_NEWS

import numpy as np
import pandas as pd
np.random.seed(RANDOM_SEED)


def main(train_candles_path=None, train_news_path=None, output_dir=None):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è"""
    start_time = time.time()
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Ç–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã
    train_candles_path = train_candles_path or TRAIN_CANDLES
    train_news_path = train_news_path or TRAIN_NEWS
    output_dir = Path(output_dir) if output_dir else MODELS_DIR
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("=" * 70)
    print("üöÄ –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò FORECAST")
    print("=" * 70)
    print(f"\nüìÅ –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
    print(f"   Train candles: {train_candles_path}")
    print(f"   Train news: {train_news_path}")
    print(f"   Output dir: {output_dir}")
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\n" + "=" * 70)
    print("–≠–¢–ê–ü 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    print("=" * 70)
    
    # –í—Ä–µ–º–µ–Ω–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –≤ config (–¥–ª—è DataLoader)
    import src.config as config
    config.TRAIN_CANDLES = train_candles_path
    config.TRAIN_NEWS = train_news_path
    
    loader = DataLoader()
    loader.load_data(mode='train')
    
    train_df = loader.get_train_data()
    all_candles = loader.get_all_candles()
    all_news = loader.get_all_news()
    
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö:")
    print(f"   –¢–∏–∫–µ—Ä–æ–≤: {train_df['ticker'].nunique()}")
    print(f"   –î–∞—Ç: {train_df['begin'].nunique()}")
    print(f"   –ü–µ—Ä–∏–æ–¥: {train_df['begin'].min()} - {train_df['begin'].max()}")
    
    # 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–∞—Ä–≥–µ—Ç–æ–≤ –¥–ª—è –≤—Å–µ—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤
    print("\n" + "=" * 70)
    print("–≠–¢–ê–ü 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–∞—Ä–≥–µ—Ç–æ–≤")
    print("=" * 70)
    
    all_candles = loader.prepare_targets_for_horizons(all_candles)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ train –¥–∞–Ω–Ω—ã–µ
    train_dates = set(train_df['begin'].unique())
    train_data = all_candles[all_candles['begin'].isin(train_dates)].copy()
    
    print(f"   –°—Ç—Ä–æ–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(train_data)}")
    
    # 3. Feature Engineering
    print("\n" + "=" * 70)
    print("–≠–¢–ê–ü 3: Feature Engineering")
    print("=" * 70)
    
    engineer = FeatureEngineer()
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –∫–æ—Ç–∏—Ä–æ–≤–æ–∫
    all_candles = engineer.create_price_features(all_candles)
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –≤—Ä–µ–º–µ–Ω–∏)
    print("\n   ‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –Ω–æ–≤–æ—Å—Ç–µ–π (–∑–∞–Ω–∏–º–∞–µ—Ç –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏)")
    print("   –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π...")
    
    # –ë—ã—Å—Ç—Ä—ã–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –¥–Ω—è–º
    news_per_day = all_news.groupby(
        all_news['publish_date'].dt.date
    ).size().reset_index(name='daily_news_count')
    news_per_day.columns = ['date', 'daily_news_count']
    news_per_day['date'] = pd.to_datetime(news_per_day['date'])
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫ –∫–æ—Ç–∏—Ä–æ–≤–∫–∞–º
    all_candles['date_only'] = all_candles['begin'].dt.date
    all_candles['date_only'] = pd.to_datetime(all_candles['date_only'])
    all_candles = all_candles.merge(
        news_per_day, 
        left_on='date_only', 
        right_on='date', 
        how='left'
    )
    all_candles['daily_news_count'] = all_candles['daily_news_count'].fillna(0)
    all_candles = all_candles.drop(['date_only', 'date'], axis=1)
    
    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    all_candles = engineer.fill_missing_values(all_candles)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feature_cols = engineer.get_feature_columns(all_candles)
    feature_cols.append('daily_news_count')  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ—Å—Ç–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    
    print(f"\n   ‚úÖ –í—Å–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_cols)}")
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ train –¥–∞–Ω–Ω—ã–µ
    train_data = all_candles[all_candles['begin'].isin(train_dates)].copy()
    
    # 4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    print("\n" + "=" * 70)
    print("–≠–¢–ê–ü 4: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")
    print("=" * 70)
    
    model = ForecastModel()
    model.train(train_data, feature_cols, val_size=0.2, verbose=True)
    
    # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    print("\n" + "=" * 70)
    print("–≠–¢–ê–ü 5: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")
    print("=" * 70)
    
    model.save(output_dir / "forecast_models.pkl")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∞–∫–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    processed_data = {
        'all_candles': all_candles,
        'feature_cols': feature_cols,
        'news_per_day': news_per_day
    }
    
    import joblib
    joblib.dump(processed_data, output_dir / "processed_data.pkl")
    print(f"   ‚úì –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
    
    # –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    elapsed_time = time.time() - start_time
    print("\n" + "=" * 70)
    print("‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print("=" * 70)
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥ ({elapsed_time/60:.2f} –º–∏–Ω—É—Ç)")
    print(f"üíæ –ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_dir}")
    print("\nüí° –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: –∑–∞–ø—É—Å—Ç–∏—Ç–µ predict.py –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ FORECAST')
    parser.add_argument('--train-candles', type=str, default=None,
                       help=f'–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –æ–±—É—á–∞—é—â–∏–º–∏ –∫–æ—Ç–∏—Ä–æ–≤–∫–∞–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {TRAIN_CANDLES})')
    parser.add_argument('--train-news', type=str, default=None,
                       help=f'–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –æ–±—É—á–∞—é—â–∏–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {TRAIN_NEWS})')
    parser.add_argument('--output-dir', type=str, default=None,
                       help=f'–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {MODELS_DIR})')
    
    args = parser.parse_args()
    
    main(
        train_candles_path=args.train_candles,
        train_news_path=args.train_news,
        output_dir=args.output_dir
    )

