"""
–ú–æ–¥–µ–ª—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Ä–æ—Å—Ç–∞
"""
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple
import joblib
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, accuracy_score
from sklearn.ensemble import GradientBoostingClassifier

from src.config import RANDOM_SEED, N_HORIZONS, MODELS_DIR

# –ü—Ä–æ–±—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å LightGBM, –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è - –∏—Å–ø–æ–ª—å–∑—É–µ–º sklearn
try:
    from lightgbm import LGBMClassifier
    USE_LIGHTGBM = True
except (ImportError, OSError):
    USE_LIGHTGBM = False
    print("‚ö†Ô∏è  LightGBM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º sklearn GradientBoostingClassifier")


class ForecastModel:
    """–ú–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Ä–æ—Å—Ç–∞ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞—Ö"""
    
    def __init__(self, n_horizons=N_HORIZONS):
        self.n_horizons = n_horizons
        self.models = {}  # –°–ª–æ–≤–∞—Ä—å –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞
        self.feature_columns = []
        
    def train(self, df: pd.DataFrame, feature_cols: List[str], 
             val_size: float = 0.2, verbose: bool = True):
        """
        –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—Å–µ—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤
        
        Args:
            df: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ —Ç–∞—Ä–≥–µ—Ç–∞–º–∏
            feature_cols: –°–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            val_size: –†–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏
            verbose: –í—ã–≤–æ–¥–∏—Ç—å –ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—É—á–µ–Ω–∏–∏
        """
        print("\nüéì –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—Å–µ—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤...")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤: {self.n_horizons}")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_cols)}")
        print(f"   –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {len(df)}")
        
        self.feature_columns = feature_cols
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN –≤ —Ç–∞—Ä–≥–µ—Ç–∞—Ö
        train_df = df.copy()
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞
        for horizon in range(1, self.n_horizons + 1):
            if verbose:
                print(f"\n   üìä –ì–æ—Ä–∏–∑–æ–Ω—Ç {horizon} –¥–Ω–µ–π:")
            
            # –¢–∞—Ä–≥–µ—Ç –¥–ª—è —ç—Ç–æ–≥–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞
            target_col = f'target_direction_{horizon}d'
            
            if target_col not in train_df.columns:
                print(f"      ‚ö†Ô∏è  –¢–∞—Ä–≥–µ—Ç {target_col} –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN –≤ —Ç–∞—Ä–≥–µ—Ç–µ –¥–ª—è —ç—Ç–æ–≥–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞
            valid_mask = train_df[target_col].notna()
            X = train_df.loc[valid_mask, feature_cols].values
            y = train_df.loc[valid_mask, target_col].values
            
            if len(y) < 100:
                print(f"      ‚ö†Ô∏è  –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö ({len(y)} —Å—Ç—Ä–æ–∫), –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ train/val
            X_train, X_val, y_train, y_val = train_test_split(
                X, y, test_size=val_size, random_state=RANDOM_SEED, stratify=y
            )
            
            # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            if USE_LIGHTGBM:
                model = LGBMClassifier(
                    n_estimators=200,
                    max_depth=6,
                    learning_rate=0.05,
                    subsample=0.8,
                    colsample_bytree=0.8,
                    random_state=RANDOM_SEED,
                    n_jobs=-1,
                    verbose=-1,
                    class_weight='balanced'
                )
                
                model.fit(
                    X_train, y_train,
                    eval_set=[(X_val, y_val)],
                    eval_metric='auc',
                    verbose=False
                )
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º sklearn GradientBoosting –µ—Å–ª–∏ LightGBM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
                model = GradientBoostingClassifier(
                    n_estimators=100,  # –ú–µ–Ω—å—à–µ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                    max_depth=5,
                    learning_rate=0.1,
                    subsample=0.8,
                    random_state=RANDOM_SEED,
                    verbose=0
                )
                
                model.fit(X_train, y_train)
            
            # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            y_pred_proba = model.predict_proba(X_val)[:, 1]
            y_pred = (y_pred_proba > 0.5).astype(int)
            
            auc = roc_auc_score(y_val, y_pred_proba)
            acc = accuracy_score(y_val, y_pred)
            
            if verbose:
                print(f"      Train size: {len(X_train)}, Val size: {len(X_val)}")
                print(f"      Positive rate: {y_train.mean():.3f}")
                print(f"      Val AUC: {auc:.4f}, Val Accuracy: {acc:.4f}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            self.models[horizon] = model
        
        print(f"\n   ‚úÖ –û–±—É—á–µ–Ω–æ {len(self.models)} –º–æ–¥–µ–ª–µ–π")
        
        return self
    
    def predict(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Ä–æ—Å—Ç–∞ –¥–ª—è –≤—Å–µ—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤
        
        Args:
            df: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
            
        Returns:
            DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ ticker, begin, p1, p2, ..., p20
        """
        print("\nüîÆ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Ä–æ—Å—Ç–∞...")
        
        if not self.models:
            raise ValueError("–ú–æ–¥–µ–ª–∏ –Ω–µ –æ–±—É—á–µ–Ω—ã! –°–Ω–∞—á–∞–ª–∞ –≤—ã–∑–æ–≤–∏—Ç–µ train()")
        
        if not self.feature_columns:
            raise ValueError("–°–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω!")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        missing_features = set(self.feature_columns) - set(df.columns)
        if missing_features:
            print(f"      ‚ö†Ô∏è  –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {missing_features}")
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –Ω—É–ª—è–º–∏
            for feat in missing_features:
                df[feat] = 0
        
        X = df[self.feature_columns].values
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞
        predictions = pd.DataFrame()
        predictions['ticker'] = df['ticker'].values
        predictions['begin'] = df['begin'].values
        
        for horizon in range(1, self.n_horizons + 1):
            if horizon in self.models:
                model = self.models[horizon]
                proba = model.predict_proba(X)[:, 1]
                
                # –ö–ª–∏–ø–ø–∏–Ω–≥ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –≤ —Ä–∞–∑—É–º–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω
                proba = np.clip(proba, 0.05, 0.95)
            else:
                # –ï—Å–ª–∏ –º–æ–¥–µ–ª–∏ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                proba = np.full(len(df), 0.5)
            
            predictions[f'p{horizon}'] = proba
        
        print(f"   ‚úì –°–æ–∑–¥–∞–Ω–æ {len(predictions)} –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è {self.n_horizons} –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤")
        print(f"\n   üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π:")
        prob_cols = [f'p{i}' for i in range(1, self.n_horizons + 1)]
        print(f"      –°—Ä–µ–¥–Ω—è—è: {predictions[prob_cols].mean().mean():.4f}")
        print(f"      Std: {predictions[prob_cols].std().mean():.4f}")
        
        return predictions
    
    def save(self, path: Path = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"""
        if path is None:
            path = MODELS_DIR / "forecast_models.pkl"
        
        print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –≤ {path}...")
        
        model_data = {
            'models': self.models,
            'feature_columns': self.feature_columns,
            'n_horizons': self.n_horizons
        }
        
        joblib.dump(model_data, path)
        print(f"   ‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(self.models)} –º–æ–¥–µ–ª–µ–π")
        
    def load(self, path: Path = None):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π"""
        if path is None:
            path = MODELS_DIR / "forecast_models.pkl"
        
        print(f"\nüìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –∏–∑ {path}...")
        
        model_data = joblib.load(path)
        self.models = model_data['models']
        self.feature_columns = model_data['feature_columns']
        self.n_horizons = model_data['n_horizons']
        
        print(f"   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.models)} –º–æ–¥–µ–ª–µ–π")
        print(f"   ‚úì –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(self.feature_columns)}")
        
        return self
    
    def get_feature_importance(self, top_n: int = 20) -> Dict[int, pd.DataFrame]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞
        
        Args:
            top_n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å {horizon: DataFrame with feature importance}
        """
        importance_dict = {}
        
        for horizon, model in self.models.items():
            try:
                importance = pd.DataFrame({
                    'feature': self.feature_columns,
                    'importance': model.feature_importances_
                })
                importance = importance.sort_values('importance', ascending=False).head(top_n)
                importance_dict[horizon] = importance
            except AttributeError:
                # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç feature_importances_
                print(f"   ‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –¥–ª—è –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞ {horizon} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç feature_importances_")
        
        return importance_dict

