"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π FORECAST
"""
import sys
import time
import argparse
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent))

from src.data_loader import DataLoader
from src.model import ForecastModel
from src.config import MODELS_DIR, PROJECT_ROOT, PUBLIC_TEST_CANDLES, PRIVATE_TEST_CANDLES, TEST_NEWS

import numpy as np
import pandas as pd
import joblib


def main(public_test_candles=None, private_test_candles=None, test_news=None, 
         models_dir=None, output_file=None):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
    start_time = time.time()
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Ç–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã
    public_test_candles = public_test_candles or PUBLIC_TEST_CANDLES
    private_test_candles = private_test_candles or PRIVATE_TEST_CANDLES
    test_news = test_news or TEST_NEWS
    models_dir = Path(models_dir) if models_dir else MODELS_DIR
    output_file = output_file or (PROJECT_ROOT / "submission.csv")
    
    print("=" * 70)
    print("üîÆ –°–û–ó–î–ê–ù–ò–ï –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô FORECAST")
    print("=" * 70)
    print(f"\nüìÅ –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
    print(f"   Public test: {public_test_candles}")
    print(f"   Private test: {private_test_candles}")
    print(f"   Test news: {test_news}")
    print(f"   Models dir: {models_dir}")
    print(f"   Output: {output_file}")
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    print("\n" + "=" * 70)
    print("–≠–¢–ê–ü 1: –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏")
    print("=" * 70)
    
    model = ForecastModel()
    model.load(models_dir / "forecast_models.pkl")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    print("\nüìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    processed_data = joblib.load(models_dir / "processed_data.pkl")
    all_candles = processed_data['all_candles']
    feature_cols = processed_data['feature_cols']
    
    print(f"   ‚úì –î–∞–Ω–Ω—ã—Ö –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(all_candles)} —Å—Ç—Ä–æ–∫")
    print(f"   ‚úì –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_cols)}")
    
    # 2. –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    print("\n" + "=" * 70)
    print("–≠–¢–ê–ü 2: –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    print("=" * 70)
    
    # –í—Ä–µ–º–µ–Ω–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –≤ config (–¥–ª—è DataLoader)
    import src.config as config
    config.PUBLIC_TEST_CANDLES = public_test_candles
    config.PRIVATE_TEST_CANDLES = private_test_candles
    config.TEST_NEWS = test_news
    
    loader = DataLoader()
    loader.load_data(mode='test')
    test_df = loader.get_test_data()
    
    print(f"   –¢–µ—Å—Ç–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫: {len(test_df)}")
    print(f"   –¢–∏–∫–µ—Ä–æ–≤: {test_df['ticker'].nunique()}")
    print(f"   –ü–µ—Ä–∏–æ–¥: {test_df['begin'].min()} - {test_df['begin'].max()}")
    
    # 3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    print("\n" + "=" * 70)
    print("–≠–¢–ê–ü 3: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    print("=" * 70)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞—Ç—ã –∏–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    test_dates = set(test_df['begin'].unique())
    test_data = all_candles[all_candles['begin'].isin(test_dates)].copy()
    
    print(f"   –°—Ç—Ä–æ–∫ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {len(test_data)}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    missing_features = set(feature_cols) - set(test_data.columns)
    if missing_features:
        print(f"   ‚ö†Ô∏è  –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {missing_features}")
        for feat in missing_features:
            test_data[feat] = 0
    
    # 4. –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    print("\n" + "=" * 70)
    print("–≠–¢–ê–ü 4: –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
    print("=" * 70)
    
    predictions = model.predict(test_data)
    
    # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n" + "=" * 70)
    print("–≠–¢–ê–ü 5: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    print("=" * 70)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ ticker –∏ begin –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
    predictions = predictions.sort_values(['ticker', 'begin']).reset_index(drop=True)
    
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–∫–µ—Ä–∞ (—Å–∞–º—ã–π —Å–≤–µ–∂–∏–π –ø—Ä–æ–≥–Ω–æ–∑)
    predictions = predictions.groupby('ticker').last().reset_index()
    
    # –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É begin, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ ticker –∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
    output_cols = ['ticker'] + [f'p{i}' for i in range(1, 21)]
    submission = predictions[output_cols].copy()
    
    submission.to_csv(output_file, index=False)
    
    print(f"\nüíæ Submission —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
    print(f"   –°—Ç—Ä–æ–∫: {len(submission)}")
    print(f"   –ö–æ–ª–æ–Ω–æ–∫: {len(submission.columns)}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
    print(f"\nüìã –ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ submission:")
    print(submission.head(10).to_string(index=False, max_cols=10))
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    prob_cols = [f'p{i}' for i in range(1, 21)]
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π:")
    print(f"   –°—Ä–µ–¥–Ω–µ–µ: {submission[prob_cols].mean().mean():.4f}")
    print(f"   Std: {submission[prob_cols].std().mean():.4f}")
    print(f"   Min: {submission[prob_cols].min().min():.4f}")
    print(f"   Max: {submission[prob_cols].max().max():.4f}")
    
    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–∫–µ—Ä–∞–º
    print(f"\nüìà –°—Ç—Ä–æ–∫ –ø–æ —Ç–∏–∫–µ—Ä–∞–º:")
    ticker_counts = submission['ticker'].value_counts().sort_index()
    for ticker, count in ticker_counts.items():
        print(f"   {ticker}: {count}")
    
    # –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    elapsed_time = time.time() - start_time
    print("\n" + "=" * 70)
    print("‚úÖ –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø –°–û–ó–î–ê–ù–´!")
    print("=" * 70)
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥ ({elapsed_time/60:.2f} –º–∏–Ω—É—Ç)")
    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π FORECAST')
    parser.add_argument('--public-test-candles', type=str, default=None,
                       help=f'–ü—É—Ç—å –∫ public test –∫–æ—Ç–∏—Ä–æ–≤–∫–∞–º (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {PUBLIC_TEST_CANDLES})')
    parser.add_argument('--private-test-candles', type=str, default=None,
                       help=f'–ü—É—Ç—å –∫ private test –∫–æ—Ç–∏—Ä–æ–≤–∫–∞–º (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {PRIVATE_TEST_CANDLES})')
    parser.add_argument('--test-news', type=str, default=None,
                       help=f'–ü—É—Ç—å –∫ test –Ω–æ–≤–æ—Å—Ç—è–º (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {TEST_NEWS})')
    parser.add_argument('--models-dir', type=str, default=None,
                       help=f'–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –æ–±—É—á–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {MODELS_DIR})')
    parser.add_argument('--output', '-o', type=str, default=None,
                       help=f'–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {PROJECT_ROOT / "submission.csv"})')
    
    args = parser.parse_args()
    
    main(
        public_test_candles=args.public_test_candles,
        private_test_candles=args.private_test_candles,
        test_news=args.test_news,
        models_dir=args.models_dir,
        output_file=args.output
    )

